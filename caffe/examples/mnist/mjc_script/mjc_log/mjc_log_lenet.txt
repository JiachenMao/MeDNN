I0929 13:14:44.901334  9926 caffe.cpp:186] Using GPUs 0
I0929 13:14:44.955742  9926 caffe.cpp:191] GPU 0: GeForce GTX TITAN X
I0929 13:14:45.898556  9926 solver.cpp:50] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "lenet_mjc"
solver_mode: GPU
device_id: 0
net: "./lenet_train_test_grouplasso.prototxt"
block_group_decay: 0.001
I0929 13:14:45.898825  9926 solver.cpp:94] Creating training net from net file: ./lenet_train_test_grouplasso.prototxt
I0929 13:14:45.899791  9926 net.cpp:316] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0929 13:14:45.899829  9926 net.cpp:316] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0929 13:14:45.899999  9926 net.cpp:52] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "./mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    breadth_decay_mult: 1
    kernel_shape_decay_mult: 1
    block_group_lasso {
      xdimen: 25
      ydimen: 5
      block_decay_mult: 1
    }
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  connectivity_mode: CONNECTED
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    breadth_decay_mult: 1
    kernel_shape_decay_mult: 1
    block_group_lasso {
      xdimen: 25
      ydimen: 5
      block_decay_mult: 1
    }
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  connectivity_mode: CONNECTED
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 1
    breadth_decay_mult: 1
    kernel_shape_decay_mult: 1
    block_group_lasso {
      xdimen: 10
      ydimen: 10
      block_decay_mult: 1
    }
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
    decay_mult: 1
    breadth_decay_mult: 1
    kernel_shape_decay_mult: 1
    block_group_lasso {
      xdimen: 10
      ydimen: 10
      block_decay_mult: 1
    }
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0929 13:14:45.900100  9926 layer_factory.hpp:77] Creating layer mnist
I0929 13:14:45.909292  9926 net.cpp:94] Creating Layer mnist
I0929 13:14:45.909349  9926 net.cpp:402] mnist -> data
I0929 13:14:45.909420  9926 net.cpp:402] mnist -> label
I0929 13:14:45.911237  9930 db_lmdb.cpp:38] Opened lmdb ./mnist_train_lmdb
I0929 13:14:45.930544  9926 data_layer.cpp:41] output data size: 64,1,28,28
I0929 13:14:45.932086  9926 net.cpp:144] Setting up mnist
I0929 13:14:45.932168  9926 net.cpp:151] Top shape: 64 1 28 28 (50176)
I0929 13:14:45.932204  9926 net.cpp:151] Top shape: 64 (64)
I0929 13:14:45.932214  9926 net.cpp:159] Memory required for data: 200960
I0929 13:14:45.932230  9926 layer_factory.hpp:77] Creating layer conv1
I0929 13:14:45.932267  9926 net.cpp:94] Creating Layer conv1
I0929 13:14:45.932289  9926 net.cpp:428] conv1 <- data
I0929 13:14:45.932314  9926 net.cpp:402] conv1 -> conv1
I0929 13:14:45.936792  9926 net.cpp:144] Setting up conv1
I0929 13:14:45.936851  9926 net.cpp:151] Top shape: 64 20 24 24 (737280)
I0929 13:14:45.936861  9926 net.cpp:159] Memory required for data: 3150080
I0929 13:14:45.936920  9926 layer_factory.hpp:77] Creating layer pool1
I0929 13:14:45.936951  9926 net.cpp:94] Creating Layer pool1
I0929 13:14:45.936962  9926 net.cpp:428] pool1 <- conv1
I0929 13:14:45.936992  9926 net.cpp:402] pool1 -> pool1
I0929 13:14:45.939419  9926 net.cpp:144] Setting up pool1
I0929 13:14:45.939451  9926 net.cpp:151] Top shape: 64 20 12 12 (184320)
I0929 13:14:45.939481  9926 net.cpp:159] Memory required for data: 3887360
I0929 13:14:45.939491  9926 layer_factory.hpp:77] Creating layer conv2
I0929 13:14:45.939522  9926 net.cpp:94] Creating Layer conv2
I0929 13:14:45.939538  9926 net.cpp:428] conv2 <- pool1
I0929 13:14:45.939553  9926 net.cpp:402] conv2 -> conv2
I0929 13:14:45.942642  9926 net.cpp:144] Setting up conv2
I0929 13:14:45.942675  9926 net.cpp:151] Top shape: 64 50 8 8 (204800)
I0929 13:14:45.942695  9926 net.cpp:159] Memory required for data: 4706560
I0929 13:14:45.942719  9926 layer_factory.hpp:77] Creating layer pool2
I0929 13:14:45.942737  9926 net.cpp:94] Creating Layer pool2
I0929 13:14:45.942746  9926 net.cpp:428] pool2 <- conv2
I0929 13:14:45.942757  9926 net.cpp:402] pool2 -> pool2
I0929 13:14:45.943753  9926 net.cpp:144] Setting up pool2
I0929 13:14:45.943784  9926 net.cpp:151] Top shape: 64 50 4 4 (51200)
I0929 13:14:45.943794  9926 net.cpp:159] Memory required for data: 4911360
I0929 13:14:45.943802  9926 layer_factory.hpp:77] Creating layer ip1
I0929 13:14:45.943820  9926 net.cpp:94] Creating Layer ip1
I0929 13:14:45.943830  9926 net.cpp:428] ip1 <- pool2
I0929 13:14:45.943842  9926 net.cpp:402] ip1 -> ip1
I0929 13:14:45.954177  9926 net.cpp:144] Setting up ip1
I0929 13:14:45.954232  9926 net.cpp:151] Top shape: 64 500 (32000)
I0929 13:14:45.954242  9926 net.cpp:159] Memory required for data: 5039360
I0929 13:14:45.954278  9926 layer_factory.hpp:77] Creating layer relu1
I0929 13:14:45.954301  9926 net.cpp:94] Creating Layer relu1
I0929 13:14:45.954324  9926 net.cpp:428] relu1 <- ip1
I0929 13:14:45.954337  9926 net.cpp:389] relu1 -> ip1 (in-place)
I0929 13:14:45.954373  9926 net.cpp:144] Setting up relu1
I0929 13:14:45.954388  9926 net.cpp:151] Top shape: 64 500 (32000)
I0929 13:14:45.954398  9926 net.cpp:159] Memory required for data: 5167360
I0929 13:14:45.954432  9926 layer_factory.hpp:77] Creating layer ip2
I0929 13:14:45.954445  9926 net.cpp:94] Creating Layer ip2
I0929 13:14:45.954453  9926 net.cpp:428] ip2 <- ip1
I0929 13:14:45.954476  9926 net.cpp:402] ip2 -> ip2
I0929 13:14:45.954879  9926 net.cpp:144] Setting up ip2
I0929 13:14:45.954926  9926 net.cpp:151] Top shape: 64 10 (640)
I0929 13:14:45.954934  9926 net.cpp:159] Memory required for data: 5169920
I0929 13:14:45.954952  9926 layer_factory.hpp:77] Creating layer loss
I0929 13:14:45.954973  9926 net.cpp:94] Creating Layer loss
I0929 13:14:45.954982  9926 net.cpp:428] loss <- ip2
I0929 13:14:45.954993  9926 net.cpp:428] loss <- label
I0929 13:14:45.955015  9926 net.cpp:402] loss -> loss
I0929 13:14:45.955049  9926 layer_factory.hpp:77] Creating layer loss
I0929 13:14:45.955255  9926 net.cpp:144] Setting up loss
I0929 13:14:45.955270  9926 net.cpp:151] Top shape: (1)
I0929 13:14:45.955277  9926 net.cpp:154]     with loss weight 1
I0929 13:14:45.955329  9926 net.cpp:159] Memory required for data: 5169924
I0929 13:14:45.955353  9926 net.cpp:220] loss needs backward computation.
I0929 13:14:45.955363  9926 net.cpp:220] ip2 needs backward computation.
I0929 13:14:45.955373  9926 net.cpp:220] relu1 needs backward computation.
I0929 13:14:45.955410  9926 net.cpp:220] ip1 needs backward computation.
I0929 13:14:45.955420  9926 net.cpp:220] pool2 needs backward computation.
I0929 13:14:45.955428  9926 net.cpp:220] conv2 needs backward computation.
I0929 13:14:45.955440  9926 net.cpp:220] pool1 needs backward computation.
I0929 13:14:45.955449  9926 net.cpp:220] conv1 needs backward computation.
I0929 13:14:45.955458  9926 net.cpp:222] mnist does not need backward computation.
I0929 13:14:45.955467  9926 net.cpp:264] This network produces output loss
I0929 13:14:45.955487  9926 net.cpp:277] Network initialization done.
I0929 13:14:45.956137  9926 solver.cpp:184] Creating test net (#0) specified by net file: ./lenet_train_test_grouplasso.prototxt
I0929 13:14:45.956198  9926 net.cpp:316] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0929 13:14:45.956384  9926 net.cpp:52] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "./mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    breadth_decay_mult: 1
    kernel_shape_decay_mult: 1
    block_group_lasso {
      xdimen: 25
      ydimen: 5
      block_decay_mult: 1
    }
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  connectivity_mode: CONNECTED
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    breadth_decay_mult: 1
    kernel_shape_decay_mult: 1
    block_group_lasso {
      xdimen: 25
      ydimen: 5
      block_decay_mult: 1
    }
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  connectivity_mode: CONNECTED
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 1
    breadth_decay_mult: 1
    kernel_shape_decay_mult: 1
    block_group_lasso {
      xdimen: 10
      ydimen: 10
      block_decay_mult: 1
    }
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
    decay_mult: 1
    breadth_decay_mult: 1
    kernel_shape_decay_mult: 1
    block_group_lasso {
      xdimen: 10
      ydimen: 10
      block_decay_mult: 1
    }
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0929 13:14:45.956511  9926 layer_factory.hpp:77] Creating layer mnist
I0929 13:14:45.956679  9926 net.cpp:94] Creating Layer mnist
I0929 13:14:45.956694  9926 net.cpp:402] mnist -> data
I0929 13:14:45.956710  9926 net.cpp:402] mnist -> label
I0929 13:14:45.958109  9932 db_lmdb.cpp:38] Opened lmdb ./mnist_test_lmdb
I0929 13:14:45.960278  9926 data_layer.cpp:41] output data size: 100,1,28,28
I0929 13:14:45.962033  9926 net.cpp:144] Setting up mnist
I0929 13:14:45.962056  9926 net.cpp:151] Top shape: 100 1 28 28 (78400)
I0929 13:14:45.962091  9926 net.cpp:151] Top shape: 100 (100)
I0929 13:14:45.962100  9926 net.cpp:159] Memory required for data: 314000
I0929 13:14:45.962119  9926 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0929 13:14:45.962147  9926 net.cpp:94] Creating Layer label_mnist_1_split
I0929 13:14:45.962155  9926 net.cpp:428] label_mnist_1_split <- label
I0929 13:14:45.962193  9926 net.cpp:402] label_mnist_1_split -> label_mnist_1_split_0
I0929 13:14:45.962209  9926 net.cpp:402] label_mnist_1_split -> label_mnist_1_split_1
I0929 13:14:45.962347  9926 net.cpp:144] Setting up label_mnist_1_split
I0929 13:14:45.962374  9926 net.cpp:151] Top shape: 100 (100)
I0929 13:14:45.962385  9926 net.cpp:151] Top shape: 100 (100)
I0929 13:14:45.962393  9926 net.cpp:159] Memory required for data: 314800
I0929 13:14:45.962402  9926 layer_factory.hpp:77] Creating layer conv1
I0929 13:14:45.962433  9926 net.cpp:94] Creating Layer conv1
I0929 13:14:45.962452  9926 net.cpp:428] conv1 <- data
I0929 13:14:45.962473  9926 net.cpp:402] conv1 -> conv1
I0929 13:14:45.967442  9926 net.cpp:144] Setting up conv1
I0929 13:14:45.967478  9926 net.cpp:151] Top shape: 100 20 24 24 (1152000)
I0929 13:14:45.967488  9926 net.cpp:159] Memory required for data: 4922800
I0929 13:14:45.967516  9926 layer_factory.hpp:77] Creating layer pool1
I0929 13:14:45.967542  9926 net.cpp:94] Creating Layer pool1
I0929 13:14:45.967551  9926 net.cpp:428] pool1 <- conv1
I0929 13:14:45.967563  9926 net.cpp:402] pool1 -> pool1
I0929 13:14:45.970166  9926 net.cpp:144] Setting up pool1
I0929 13:14:45.970188  9926 net.cpp:151] Top shape: 100 20 12 12 (288000)
I0929 13:14:45.970219  9926 net.cpp:159] Memory required for data: 6074800
I0929 13:14:45.970229  9926 layer_factory.hpp:77] Creating layer conv2
I0929 13:14:45.970265  9926 net.cpp:94] Creating Layer conv2
I0929 13:14:45.970283  9926 net.cpp:428] conv2 <- pool1
I0929 13:14:45.970310  9926 net.cpp:402] conv2 -> conv2
I0929 13:14:45.973176  9926 net.cpp:144] Setting up conv2
I0929 13:14:45.973197  9926 net.cpp:151] Top shape: 100 50 8 8 (320000)
I0929 13:14:45.973217  9926 net.cpp:159] Memory required for data: 7354800
I0929 13:14:45.973240  9926 layer_factory.hpp:77] Creating layer pool2
I0929 13:14:45.973268  9926 net.cpp:94] Creating Layer pool2
I0929 13:14:45.973278  9926 net.cpp:428] pool2 <- conv2
I0929 13:14:45.973291  9926 net.cpp:402] pool2 -> pool2
I0929 13:14:45.973588  9926 net.cpp:144] Setting up pool2
I0929 13:14:45.973616  9926 net.cpp:151] Top shape: 100 50 4 4 (80000)
I0929 13:14:45.973635  9926 net.cpp:159] Memory required for data: 7674800
I0929 13:14:45.973644  9926 layer_factory.hpp:77] Creating layer ip1
I0929 13:14:45.973659  9926 net.cpp:94] Creating Layer ip1
I0929 13:14:45.973667  9926 net.cpp:428] ip1 <- pool2
I0929 13:14:45.973680  9926 net.cpp:402] ip1 -> ip1
I0929 13:14:45.984200  9926 net.cpp:144] Setting up ip1
I0929 13:14:45.984243  9926 net.cpp:151] Top shape: 100 500 (50000)
I0929 13:14:45.984254  9926 net.cpp:159] Memory required for data: 7874800
I0929 13:14:45.984293  9926 layer_factory.hpp:77] Creating layer relu1
I0929 13:14:45.984319  9926 net.cpp:94] Creating Layer relu1
I0929 13:14:45.984328  9926 net.cpp:428] relu1 <- ip1
I0929 13:14:45.984343  9926 net.cpp:389] relu1 -> ip1 (in-place)
I0929 13:14:45.984355  9926 net.cpp:144] Setting up relu1
I0929 13:14:45.984366  9926 net.cpp:151] Top shape: 100 500 (50000)
I0929 13:14:45.984378  9926 net.cpp:159] Memory required for data: 8074800
I0929 13:14:45.984387  9926 layer_factory.hpp:77] Creating layer ip2
I0929 13:14:45.984416  9926 net.cpp:94] Creating Layer ip2
I0929 13:14:45.984434  9926 net.cpp:428] ip2 <- ip1
I0929 13:14:45.984447  9926 net.cpp:402] ip2 -> ip2
I0929 13:14:45.984872  9926 net.cpp:144] Setting up ip2
I0929 13:14:45.984899  9926 net.cpp:151] Top shape: 100 10 (1000)
I0929 13:14:45.984938  9926 net.cpp:159] Memory required for data: 8078800
I0929 13:14:45.984988  9926 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0929 13:14:45.985018  9926 net.cpp:94] Creating Layer ip2_ip2_0_split
I0929 13:14:45.985060  9926 net.cpp:428] ip2_ip2_0_split <- ip2
I0929 13:14:45.985085  9926 net.cpp:402] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0929 13:14:45.985101  9926 net.cpp:402] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0929 13:14:45.985219  9926 net.cpp:144] Setting up ip2_ip2_0_split
I0929 13:14:45.985237  9926 net.cpp:151] Top shape: 100 10 (1000)
I0929 13:14:45.985249  9926 net.cpp:151] Top shape: 100 10 (1000)
I0929 13:14:45.985257  9926 net.cpp:159] Memory required for data: 8086800
I0929 13:14:45.985266  9926 layer_factory.hpp:77] Creating layer accuracy
I0929 13:14:45.985288  9926 net.cpp:94] Creating Layer accuracy
I0929 13:14:45.985298  9926 net.cpp:428] accuracy <- ip2_ip2_0_split_0
I0929 13:14:45.985308  9926 net.cpp:428] accuracy <- label_mnist_1_split_0
I0929 13:14:45.985319  9926 net.cpp:402] accuracy -> accuracy
I0929 13:14:45.985373  9926 net.cpp:144] Setting up accuracy
I0929 13:14:45.985397  9926 net.cpp:151] Top shape: (1)
I0929 13:14:45.985405  9926 net.cpp:159] Memory required for data: 8086804
I0929 13:14:45.985414  9926 layer_factory.hpp:77] Creating layer loss
I0929 13:14:45.985437  9926 net.cpp:94] Creating Layer loss
I0929 13:14:45.985450  9926 net.cpp:428] loss <- ip2_ip2_0_split_1
I0929 13:14:45.985461  9926 net.cpp:428] loss <- label_mnist_1_split_1
I0929 13:14:45.985471  9926 net.cpp:402] loss -> loss
I0929 13:14:45.985497  9926 layer_factory.hpp:77] Creating layer loss
I0929 13:14:45.985754  9926 net.cpp:144] Setting up loss
I0929 13:14:45.985770  9926 net.cpp:151] Top shape: (1)
I0929 13:14:45.985790  9926 net.cpp:154]     with loss weight 1
I0929 13:14:45.985807  9926 net.cpp:159] Memory required for data: 8086808
I0929 13:14:45.985816  9926 net.cpp:220] loss needs backward computation.
I0929 13:14:45.985839  9926 net.cpp:222] accuracy does not need backward computation.
I0929 13:14:45.985851  9926 net.cpp:220] ip2_ip2_0_split needs backward computation.
I0929 13:14:45.985859  9926 net.cpp:220] ip2 needs backward computation.
I0929 13:14:45.985869  9926 net.cpp:220] relu1 needs backward computation.
I0929 13:14:45.985888  9926 net.cpp:220] ip1 needs backward computation.
I0929 13:14:45.985896  9926 net.cpp:220] pool2 needs backward computation.
I0929 13:14:45.985905  9926 net.cpp:220] conv2 needs backward computation.
I0929 13:14:45.985914  9926 net.cpp:220] pool1 needs backward computation.
I0929 13:14:45.985924  9926 net.cpp:220] conv1 needs backward computation.
I0929 13:14:45.985935  9926 net.cpp:222] label_mnist_1_split does not need backward computation.
I0929 13:14:45.985945  9926 net.cpp:222] mnist does not need backward computation.
I0929 13:14:45.985954  9926 net.cpp:264] This network produces output accuracy
I0929 13:14:45.985962  9926 net.cpp:264] This network produces output loss
I0929 13:14:45.985983  9926 net.cpp:277] Network initialization done.
I0929 13:14:45.986064  9926 solver.cpp:62] Solver scaffolding done.
I0929 13:14:45.991920  9926 caffe.cpp:220] Starting Optimization
I0929 13:14:45.991943  9926 solver.cpp:290] Solving LeNet
I0929 13:14:45.991952  9926 solver.cpp:291] Learning Rate Policy: inv
I0929 13:14:45.992753  9926 solver.cpp:348] Iteration 0, Testing net (#0)
I0929 13:14:47.070889  9926 solver.cpp:415]     Test net output #0: accuracy = 0.1028
I0929 13:14:47.070956  9926 solver.cpp:415]     Test net output #1: loss = 2.33187 (* 1 = 2.33187 loss)
I0929 13:14:47.085525  9926 solver.cpp:231] Iteration 0, loss = 2.30729
I0929 13:14:47.085554  9926 solver.cpp:247]     Train net output #0: loss = 2.30729 (* 1 = 2.30729 loss)
I0929 13:14:47.085619  9926 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0929 13:14:47.089561  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	100	0.152	100	0.1635	100	0.08	100	
I0929 13:14:47.089650  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	100	0	100	0	100	0	100	
I0929 13:14:47.089696  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	100	0	100	0	100	0	100	
I0929 13:14:47.089861  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:14:47.093396  9926 solver.cpp:260]     Total regularization terms: 1.68809 loss+regular. : 3.99538
I0929 13:14:48.865723  9926 solver.cpp:231] Iteration 100, loss = 0.215398
I0929 13:14:48.865798  9926 solver.cpp:247]     Train net output #0: loss = 0.215398 (* 1 = 0.215398 loss)
I0929 13:14:48.865815  9926 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I0929 13:14:48.869065  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	0.416	0	0.84425	17.4	0.22	0	
I0929 13:14:48.869331  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:14:48.869367  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	17.4	0	0	
I0929 13:14:48.869446  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:14:48.871593  9926 solver.cpp:260]     Total regularization terms: 1.65554 loss+regular. : 1.87094
I0929 13:14:50.594797  9926 solver.cpp:231] Iteration 200, loss = 0.146353
I0929 13:14:50.594868  9926 solver.cpp:247]     Train net output #0: loss = 0.146353 (* 1 = 0.146353 loss)
I0929 13:14:50.594887  9926 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I0929 13:14:50.599835  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	0.36	0	1.1185	12.6	0.28	0	
I0929 13:14:50.600088  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:14:50.600124  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	12.6	0	0	
I0929 13:14:50.600194  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:14:50.602526  9926 solver.cpp:260]     Total regularization terms: 1.60559 loss+regular. : 1.75194
I0929 13:14:52.330749  9926 solver.cpp:231] Iteration 300, loss = 0.190823
I0929 13:14:52.330842  9926 solver.cpp:247]     Train net output #0: loss = 0.190823 (* 1 = 0.190823 loss)
I0929 13:14:52.330857  9926 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I0929 13:14:52.335851  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	0.668	0	1.58725	13.4	0.52	0	
I0929 13:14:52.336130  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:14:52.336165  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	13.4	0	0	
I0929 13:14:52.336251  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:14:52.338330  9926 solver.cpp:260]     Total regularization terms: 1.55559 loss+regular. : 1.74641
I0929 13:14:54.023254  9926 solver.cpp:231] Iteration 400, loss = 0.0840195
I0929 13:14:54.023327  9926 solver.cpp:247]     Train net output #0: loss = 0.0840195 (* 1 = 0.0840195 loss)
I0929 13:14:54.023340  9926 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I0929 13:14:54.028349  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	0.824	0	1.8255	13.8	0.3	0	
I0929 13:14:54.028604  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:14:54.028635  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	13.8	0	0	
I0929 13:14:54.028702  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:14:54.030917  9926 solver.cpp:260]     Total regularization terms: 1.50448 loss+regular. : 1.5885
I0929 13:14:55.699175  9926 solver.cpp:348] Iteration 500, Testing net (#0)
I0929 13:14:56.673550  9926 solver.cpp:415]     Test net output #0: accuracy = 0.973
I0929 13:14:56.673627  9926 solver.cpp:415]     Test net output #1: loss = 0.083552 (* 1 = 0.083552 loss)
I0929 13:14:56.683624  9926 solver.cpp:231] Iteration 500, loss = 0.0824674
I0929 13:14:56.683653  9926 solver.cpp:247]     Train net output #0: loss = 0.0824674 (* 1 = 0.0824674 loss)
I0929 13:14:56.683666  9926 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I0929 13:14:56.688717  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	0.788	0	2.0435	13.6	0.5	0	
I0929 13:14:56.688959  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:14:56.689010  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	13.6	0	0	
I0929 13:14:56.689092  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:14:56.691366  9926 solver.cpp:260]     Total regularization terms: 1.45447 loss+regular. : 1.53694
I0929 13:14:58.472136  9926 solver.cpp:231] Iteration 600, loss = 0.0755506
I0929 13:14:58.472214  9926 solver.cpp:247]     Train net output #0: loss = 0.0755506 (* 1 = 0.0755506 loss)
I0929 13:14:58.472229  9926 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I0929 13:14:58.476148  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	0.972	0	2.2375	16.6	0.52	0	
I0929 13:14:58.476411  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:14:58.476446  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	16.6	0	0	
I0929 13:14:58.476552  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:14:58.478806  9926 solver.cpp:260]     Total regularization terms: 1.40427 loss+regular. : 1.47982
I0929 13:15:00.222517  9926 solver.cpp:231] Iteration 700, loss = 0.140956
I0929 13:15:00.222579  9926 solver.cpp:247]     Train net output #0: loss = 0.140956 (* 1 = 0.140956 loss)
I0929 13:15:00.222592  9926 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I0929 13:15:00.227855  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	1.128	0	2.51325	16	0.6	0	
I0929 13:15:00.228093  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:00.228127  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	16	0	0	
I0929 13:15:00.228194  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:00.230304  9926 solver.cpp:260]     Total regularization terms: 1.35513 loss+regular. : 1.49608
I0929 13:15:01.910869  9926 solver.cpp:231] Iteration 800, loss = 0.259605
I0929 13:15:01.910919  9926 solver.cpp:247]     Train net output #0: loss = 0.259605 (* 1 = 0.259605 loss)
I0929 13:15:01.910929  9926 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I0929 13:15:01.916833  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	1.032	2	2.393	13.6	0.5	0	
I0929 13:15:01.917073  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:01.917104  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	2	0	13.6	0	0	
I0929 13:15:01.917163  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:01.919139  9926 solver.cpp:260]     Total regularization terms: 1.30712 loss+regular. : 1.56673
I0929 13:15:03.709663  9926 solver.cpp:231] Iteration 900, loss = 0.142936
I0929 13:15:03.709779  9926 solver.cpp:247]     Train net output #0: loss = 0.142936 (* 1 = 0.142936 loss)
I0929 13:15:03.709794  9926 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I0929 13:15:03.713312  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	1.404	0	2.8285	16.8	0.52	0	
I0929 13:15:03.713626  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:03.713667  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	16.8	0	0	
I0929 13:15:03.713793  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:03.716111  9926 solver.cpp:260]     Total regularization terms: 1.25958 loss+regular. : 1.40252
I0929 13:15:05.525662  9926 solver.cpp:348] Iteration 1000, Testing net (#0)
I0929 13:15:06.561177  9926 solver.cpp:415]     Test net output #0: accuracy = 0.981
I0929 13:15:06.561275  9926 solver.cpp:415]     Test net output #1: loss = 0.0624056 (* 1 = 0.0624056 loss)
I0929 13:15:06.573639  9926 solver.cpp:231] Iteration 1000, loss = 0.115206
I0929 13:15:06.573707  9926 solver.cpp:247]     Train net output #0: loss = 0.115206 (* 1 = 0.115206 loss)
I0929 13:15:06.573731  9926 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I0929 13:15:06.577672  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	1.672	0	3.05375	18.8	0.62	0	
I0929 13:15:06.577975  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:06.578040  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	18.8	0	0	
I0929 13:15:06.578147  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:06.580693  9926 solver.cpp:260]     Total regularization terms: 1.21123 loss+regular. : 1.32643
I0929 13:15:08.320425  9926 solver.cpp:231] Iteration 1100, loss = 0.0136274
I0929 13:15:08.320497  9926 solver.cpp:247]     Train net output #0: loss = 0.0136273 (* 1 = 0.0136273 loss)
I0929 13:15:08.320513  9926 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I0929 13:15:08.323789  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	1.484	0	3.12575	17.8	0.56	0	
I0929 13:15:08.324082  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:08.324138  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	17.8	0	0	
I0929 13:15:08.324271  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:08.326732  9926 solver.cpp:260]     Total regularization terms: 1.16511 loss+regular. : 1.17874
I0929 13:15:10.065464  9926 solver.cpp:231] Iteration 1200, loss = 0.0177912
I0929 13:15:10.065546  9926 solver.cpp:247]     Train net output #0: loss = 0.0177911 (* 1 = 0.0177911 loss)
I0929 13:15:10.065562  9926 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I0929 13:15:10.069942  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	1.68	0	3.387	18.8	0.56	0	
I0929 13:15:10.070214  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:10.070256  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	18.8	0	0	
I0929 13:15:10.070343  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:10.072667  9926 solver.cpp:260]     Total regularization terms: 1.1208 loss+regular. : 1.13859
I0929 13:15:11.795457  9926 solver.cpp:231] Iteration 1300, loss = 0.0147018
I0929 13:15:11.795539  9926 solver.cpp:247]     Train net output #0: loss = 0.0147017 (* 1 = 0.0147017 loss)
I0929 13:15:11.795555  9926 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I0929 13:15:11.798871  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	1.8	0	3.621	19	0.66	0	
I0929 13:15:11.799151  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:11.799191  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	19	0	0	
I0929 13:15:11.799342  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:11.801759  9926 solver.cpp:260]     Total regularization terms: 1.07608 loss+regular. : 1.09079
I0929 13:15:13.570194  9926 solver.cpp:231] Iteration 1400, loss = 0.0151513
I0929 13:15:13.570264  9926 solver.cpp:247]     Train net output #0: loss = 0.0151512 (* 1 = 0.0151512 loss)
I0929 13:15:13.570278  9926 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I0929 13:15:13.575450  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	2.04	0	3.76975	18.4	0.58	0	
I0929 13:15:13.575722  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:13.575762  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	18.4	0	0	
I0929 13:15:13.575846  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:13.578099  9926 solver.cpp:260]     Total regularization terms: 1.03195 loss+regular. : 1.0471
I0929 13:15:15.341385  9926 solver.cpp:348] Iteration 1500, Testing net (#0)
I0929 13:15:16.319574  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9836
I0929 13:15:16.319638  9926 solver.cpp:415]     Test net output #1: loss = 0.054791 (* 1 = 0.054791 loss)
I0929 13:15:16.329115  9926 solver.cpp:231] Iteration 1500, loss = 0.101398
I0929 13:15:16.329145  9926 solver.cpp:247]     Train net output #0: loss = 0.101398 (* 1 = 0.101398 loss)
I0929 13:15:16.329160  9926 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I0929 13:15:16.334779  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	2.28	0	4.007	18.8	0.62	10	
I0929 13:15:16.335034  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:16.335068  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	18.8	0	10	
I0929 13:15:16.335155  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:16.337184  9926 solver.cpp:260]     Total regularization terms: 0.989336 loss+regular. : 1.09073
I0929 13:15:18.106937  9926 solver.cpp:231] Iteration 1600, loss = 0.143903
I0929 13:15:18.107022  9926 solver.cpp:247]     Train net output #0: loss = 0.143903 (* 1 = 0.143903 loss)
I0929 13:15:18.107035  9926 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I0929 13:15:18.111220  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	2.328	2	4.20525	21.2	0.62	0	
I0929 13:15:18.111639  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:18.111703  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	2	0	21.2	0	0	
I0929 13:15:18.111850  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:18.114857  9926 solver.cpp:260]     Total regularization terms: 0.947177 loss+regular. : 1.09108
I0929 13:15:19.901634  9926 solver.cpp:231] Iteration 1700, loss = 0.0298475
I0929 13:15:19.901721  9926 solver.cpp:247]     Train net output #0: loss = 0.0298473 (* 1 = 0.0298473 loss)
I0929 13:15:19.901737  9926 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I0929 13:15:19.905118  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	2.324	0	4.403	21.6	0.72	0	
I0929 13:15:19.905478  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:19.905540  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	21.6	0	0	
I0929 13:15:19.905705  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:19.908844  9926 solver.cpp:260]     Total regularization terms: 0.906275 loss+regular. : 0.936123
I0929 13:15:21.605733  9926 solver.cpp:231] Iteration 1800, loss = 0.0240966
I0929 13:15:21.605794  9926 solver.cpp:247]     Train net output #0: loss = 0.0240964 (* 1 = 0.0240964 loss)
I0929 13:15:21.605805  9926 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I0929 13:15:21.611593  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	2.66	0	4.6275	21.4	0.7	0	
I0929 13:15:21.611841  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:21.611872  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	21.4	0	0	
I0929 13:15:21.611935  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:21.613884  9926 solver.cpp:260]     Total regularization terms: 0.865797 loss+regular. : 0.889893
I0929 13:15:23.346953  9926 solver.cpp:231] Iteration 1900, loss = 0.114134
I0929 13:15:23.347028  9926 solver.cpp:247]     Train net output #0: loss = 0.114134 (* 1 = 0.114134 loss)
I0929 13:15:23.347043  9926 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I0929 13:15:23.350402  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	2.892	0	4.887	22.6	0.74	0	
I0929 13:15:23.350685  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:23.350726  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	22.6	0	0	
I0929 13:15:23.350857  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:23.353351  9926 solver.cpp:260]     Total regularization terms: 0.825152 loss+regular. : 0.939286
I0929 13:15:25.132045  9926 solver.cpp:348] Iteration 2000, Testing net (#0)
I0929 13:15:26.123085  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9853
I0929 13:15:26.123152  9926 solver.cpp:415]     Test net output #1: loss = 0.0492661 (* 1 = 0.0492661 loss)
I0929 13:15:26.132647  9926 solver.cpp:231] Iteration 2000, loss = 0.0328868
I0929 13:15:26.132675  9926 solver.cpp:247]     Train net output #0: loss = 0.0328868 (* 1 = 0.0328868 loss)
I0929 13:15:26.132689  9926 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I0929 13:15:26.138380  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	3.1	0	5.257	23.2	0.76	0	
I0929 13:15:26.138614  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:26.138648  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	23.2	0	0	
I0929 13:15:26.138713  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:26.140835  9926 solver.cpp:260]     Total regularization terms: 0.785945 loss+regular. : 0.818832
I0929 13:15:27.825389  9926 solver.cpp:231] Iteration 2100, loss = 0.0119338
I0929 13:15:27.825451  9926 solver.cpp:247]     Train net output #0: loss = 0.0119338 (* 1 = 0.0119338 loss)
I0929 13:15:27.825467  9926 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I0929 13:15:27.831090  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	3.084	0	5.369	21.6	0.82	0	
I0929 13:15:27.831348  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:27.831384  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	21.6	0	0	
I0929 13:15:27.831459  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:27.833639  9926 solver.cpp:260]     Total regularization terms: 0.749101 loss+regular. : 0.761035
I0929 13:15:29.521508  9926 solver.cpp:231] Iteration 2200, loss = 0.0283458
I0929 13:15:29.521569  9926 solver.cpp:247]     Train net output #0: loss = 0.0283458 (* 1 = 0.0283458 loss)
I0929 13:15:29.521580  9926 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I0929 13:15:29.527268  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	3.372	0	5.68225	22.4	0.9	0	
I0929 13:15:29.527523  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:29.527559  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	22.4	0	0	
I0929 13:15:29.527623  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:29.529614  9926 solver.cpp:260]     Total regularization terms: 0.711743 loss+regular. : 0.740089
I0929 13:15:31.214803  9926 solver.cpp:231] Iteration 2300, loss = 0.140136
I0929 13:15:31.214869  9926 solver.cpp:247]     Train net output #0: loss = 0.140136 (* 1 = 0.140136 loss)
I0929 13:15:31.214885  9926 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I0929 13:15:31.220633  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	3.624	0	5.9855	23.8	0.8	0	
I0929 13:15:31.220885  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:31.220921  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	23.8	0	0	
I0929 13:15:31.220994  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:31.223098  9926 solver.cpp:260]     Total regularization terms: 0.674601 loss+regular. : 0.814738
I0929 13:15:32.907979  9926 solver.cpp:231] Iteration 2400, loss = 0.0346311
I0929 13:15:32.908036  9926 solver.cpp:247]     Train net output #0: loss = 0.034631 (* 1 = 0.034631 loss)
I0929 13:15:32.908047  9926 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I0929 13:15:32.913596  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	3.952	0	6.43475	23.8	0.96	0	
I0929 13:15:32.913844  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:32.913877  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	23.8	0	0	
I0929 13:15:32.913944  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:32.916049  9926 solver.cpp:260]     Total regularization terms: 0.640117 loss+regular. : 0.674748
I0929 13:15:34.591361  9926 solver.cpp:348] Iteration 2500, Testing net (#0)
I0929 13:15:35.675372  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9746
I0929 13:15:35.675441  9926 solver.cpp:415]     Test net output #1: loss = 0.0793297 (* 1 = 0.0793297 loss)
I0929 13:15:35.689242  9926 solver.cpp:231] Iteration 2500, loss = 0.071208
I0929 13:15:35.689316  9926 solver.cpp:247]     Train net output #0: loss = 0.0712079 (* 1 = 0.0712079 loss)
I0929 13:15:35.689373  9926 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I0929 13:15:35.692281  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	3.964	0	6.672	23.4	0.96	0	
I0929 13:15:35.692564  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:35.692615  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	23.4	0	0	
I0929 13:15:35.692740  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:35.695652  9926 solver.cpp:260]     Total regularization terms: 0.604785 loss+regular. : 0.675993
I0929 13:15:37.512235  9926 solver.cpp:231] Iteration 2600, loss = 0.123685
I0929 13:15:37.512316  9926 solver.cpp:247]     Train net output #0: loss = 0.123685 (* 1 = 0.123685 loss)
I0929 13:15:37.512336  9926 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I0929 13:15:37.515599  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	4.152	0	7.14075	24.4	0.9	0	
I0929 13:15:37.515879  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:37.515923  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	24.4	0	0	
I0929 13:15:37.516057  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:37.518484  9926 solver.cpp:260]     Total regularization terms: 0.571614 loss+regular. : 0.695299
I0929 13:15:39.270247  9926 solver.cpp:231] Iteration 2700, loss = 0.102754
I0929 13:15:39.270303  9926 solver.cpp:247]     Train net output #0: loss = 0.102754 (* 1 = 0.102754 loss)
I0929 13:15:39.270328  9926 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I0929 13:15:39.274271  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	4.428	0	7.64325	23	1.18	0	
I0929 13:15:39.274564  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:39.274600  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	23	0	0	
I0929 13:15:39.274715  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:39.276995  9926 solver.cpp:260]     Total regularization terms: 0.539749 loss+regular. : 0.642502
I0929 13:15:41.034157  9926 solver.cpp:231] Iteration 2800, loss = 0.00688768
I0929 13:15:41.034231  9926 solver.cpp:247]     Train net output #0: loss = 0.00688761 (* 1 = 0.00688761 loss)
I0929 13:15:41.034245  9926 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I0929 13:15:41.038262  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	4.812	0	8.41325	24.2	1.32	0	
I0929 13:15:41.038620  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:41.038678  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	24.2	0	0	
I0929 13:15:41.038820  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:41.041970  9926 solver.cpp:260]     Total regularization terms: 0.507296 loss+regular. : 0.514184
I0929 13:15:42.736600  9926 solver.cpp:231] Iteration 2900, loss = 0.0795543
I0929 13:15:42.736663  9926 solver.cpp:247]     Train net output #0: loss = 0.0795541 (* 1 = 0.0795541 loss)
I0929 13:15:42.736680  9926 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I0929 13:15:42.742435  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	5.02	0	8.9955	25	1.12	0	
I0929 13:15:42.742686  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:42.742728  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	25	0	0	
I0929 13:15:42.742808  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:42.744896  9926 solver.cpp:260]     Total regularization terms: 0.475063 loss+regular. : 0.554618
I0929 13:15:44.436838  9926 solver.cpp:348] Iteration 3000, Testing net (#0)
I0929 13:15:45.425215  9926 solver.cpp:415]     Test net output #0: accuracy = 0.983
I0929 13:15:45.425444  9926 solver.cpp:415]     Test net output #1: loss = 0.0580015 (* 1 = 0.0580015 loss)
I0929 13:15:45.434733  9926 solver.cpp:231] Iteration 3000, loss = 0.0221438
I0929 13:15:45.434779  9926 solver.cpp:247]     Train net output #0: loss = 0.0221437 (* 1 = 0.0221437 loss)
I0929 13:15:45.434792  9926 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I0929 13:15:45.440563  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	4.316	0	9.03475	21	1.16	0	
I0929 13:15:45.440803  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:45.440835  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	21	0	0	
I0929 13:15:45.440906  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:45.442951  9926 solver.cpp:260]     Total regularization terms: 0.446901 loss+regular. : 0.469045
I0929 13:15:47.218617  9926 solver.cpp:231] Iteration 3100, loss = 0.0243732
I0929 13:15:47.218698  9926 solver.cpp:247]     Train net output #0: loss = 0.024373 (* 1 = 0.024373 loss)
I0929 13:15:47.218713  9926 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I0929 13:15:47.222429  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	5.128	0	10.193	21	1.34	0	
I0929 13:15:47.222708  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:47.222761  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	21	0	0	
I0929 13:15:47.222898  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:47.225193  9926 solver.cpp:260]     Total regularization terms: 0.419386 loss+regular. : 0.443759
I0929 13:15:49.015100  9926 solver.cpp:231] Iteration 3200, loss = 0.0319285
I0929 13:15:49.015182  9926 solver.cpp:247]     Train net output #0: loss = 0.0319283 (* 1 = 0.0319283 loss)
I0929 13:15:49.015200  9926 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I0929 13:15:49.018465  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	5.596	0	11.5665	24.4	1.4	0	
I0929 13:15:49.018759  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:49.018805  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	24.4	0	0	
I0929 13:15:49.018962  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:49.021464  9926 solver.cpp:260]     Total regularization terms: 0.391263 loss+regular. : 0.423191
I0929 13:15:50.788198  9926 solver.cpp:231] Iteration 3300, loss = 0.0380609
I0929 13:15:50.788266  9926 solver.cpp:247]     Train net output #0: loss = 0.0380607 (* 1 = 0.0380607 loss)
I0929 13:15:50.788291  9926 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I0929 13:15:50.792366  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	5.944	0	12.8862	23.6	1.56	0	
I0929 13:15:50.792706  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:50.792763  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	23.6	0	0	
I0929 13:15:50.792920  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0;		(10,10):0;		
I0929 13:15:50.795862  9926 solver.cpp:260]     Total regularization terms: 0.365587 loss+regular. : 0.403648
I0929 13:15:52.493507  9926 solver.cpp:231] Iteration 3400, loss = 0.0350992
I0929 13:15:52.493582  9926 solver.cpp:247]     Train net output #0: loss = 0.035099 (* 1 = 0.035099 loss)
I0929 13:15:52.493593  9926 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I0929 13:15:52.499153  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	5.936	0	13.927	21	1.52	0	
I0929 13:15:52.499400  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:52.499434  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	21	0	0	
I0929 13:15:52.499518  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0.025;		(10,10):0;		
I0929 13:15:52.501646  9926 solver.cpp:260]     Total regularization terms: 0.340573 loss+regular. : 0.375672
I0929 13:15:54.180655  9926 solver.cpp:348] Iteration 3500, Testing net (#0)
I0929 13:15:55.160917  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9777
I0929 13:15:55.161012  9926 solver.cpp:415]     Test net output #1: loss = 0.0699941 (* 1 = 0.0699941 loss)
I0929 13:15:55.170599  9926 solver.cpp:231] Iteration 3500, loss = 0.0222277
I0929 13:15:55.170627  9926 solver.cpp:247]     Train net output #0: loss = 0.0222276 (* 1 = 0.0222276 loss)
I0929 13:15:55.170646  9926 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I0929 13:15:55.176208  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	6.232	0	16.5055	21.6	1.6	10	
I0929 13:15:55.176450  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:55.176483  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	21.6	0	10	
I0929 13:15:55.176575  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0.25;		(10,10):0;		
I0929 13:15:55.178733  9926 solver.cpp:260]     Total regularization terms: 0.318641 loss+regular. : 0.340869
I0929 13:15:56.875349  9926 solver.cpp:231] Iteration 3600, loss = 0.134623
I0929 13:15:56.875425  9926 solver.cpp:247]     Train net output #0: loss = 0.134623 (* 1 = 0.134623 loss)
I0929 13:15:56.875439  9926 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I0929 13:15:56.879359  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	6.368	0	18.9638	22.8	1.54	0	
I0929 13:15:56.879660  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:56.879700  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	22.8	0	0	
I0929 13:15:56.879911  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):0.575;		(10,10):0;		
I0929 13:15:56.882164  9926 solver.cpp:260]     Total regularization terms: 0.30066 loss+regular. : 0.435283
I0929 13:15:58.677788  9926 solver.cpp:231] Iteration 3700, loss = 0.0513565
I0929 13:15:58.677845  9926 solver.cpp:247]     Train net output #0: loss = 0.0513563 (* 1 = 0.0513563 loss)
I0929 13:15:58.677860  9926 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I0929 13:15:58.681658  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	6.696	0	23.6677	23.6	2.08	0	
I0929 13:15:58.681982  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:15:58.682029  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	23.6	0	0	
I0929 13:15:58.682315  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):1.625;		(10,10):0;		
I0929 13:15:58.684834  9926 solver.cpp:260]     Total regularization terms: 0.28193 loss+regular. : 0.333286
I0929 13:16:00.377671  9926 solver.cpp:231] Iteration 3800, loss = 0.0360513
I0929 13:16:00.377728  9926 solver.cpp:247]     Train net output #0: loss = 0.0360511 (* 1 = 0.0360511 loss)
I0929 13:16:00.377743  9926 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I0929 13:16:00.383373  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	7.152	0	28.96	24.2	2.12	0	
I0929 13:16:00.383635  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:16:00.383674  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	24.2	0	0	
I0929 13:16:00.383991  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):4.125;		(10,10):0;		
I0929 13:16:00.386106  9926 solver.cpp:260]     Total regularization terms: 0.262036 loss+regular. : 0.298087
I0929 13:16:02.098493  9926 solver.cpp:231] Iteration 3900, loss = 0.0684172
I0929 13:16:02.098562  9926 solver.cpp:247]     Train net output #0: loss = 0.068417 (* 1 = 0.068417 loss)
I0929 13:16:02.098577  9926 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I0929 13:16:02.101693  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	7.292	0	34.047	23.6	1.82	0	
I0929 13:16:02.102022  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:16:02.102068  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	23.6	0	0	
I0929 13:16:02.102726  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):5.325;		(10,10):0;		
I0929 13:16:02.105218  9926 solver.cpp:260]     Total regularization terms: 0.248459 loss+regular. : 0.316876
I0929 13:16:03.877235  9926 solver.cpp:348] Iteration 4000, Testing net (#0)
I0929 13:16:04.871012  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9835
I0929 13:16:04.871105  9926 solver.cpp:415]     Test net output #1: loss = 0.0557089 (* 1 = 0.0557089 loss)
I0929 13:16:04.880642  9926 solver.cpp:231] Iteration 4000, loss = 0.0947198
I0929 13:16:04.880671  9926 solver.cpp:247]     Train net output #0: loss = 0.0947196 (* 1 = 0.0947196 loss)
I0929 13:16:04.880684  9926 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I0929 13:16:04.886250  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	6.956	0	38.6845	22.6	2.14	0	
I0929 13:16:04.886500  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:16:04.886531  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	22.6	0	0	
I0929 13:16:04.886916  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):7.625;		(10,10):0;		
I0929 13:16:04.889070  9926 solver.cpp:260]     Total regularization terms: 0.242022 loss+regular. : 0.336741
I0929 13:16:06.604163  9926 solver.cpp:231] Iteration 4100, loss = 0.0571131
I0929 13:16:06.604240  9926 solver.cpp:247]     Train net output #0: loss = 0.0571129 (* 1 = 0.0571129 loss)
I0929 13:16:06.604256  9926 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I0929 13:16:06.607343  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	7.42	0	44.3018	23.2	2.06	0	
I0929 13:16:06.607671  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:16:06.607712  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	23.2	0	0	
I0929 13:16:06.608747  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):10.4;		(10,10):0;		
I0929 13:16:06.611232  9926 solver.cpp:260]     Total regularization terms: 0.232489 loss+regular. : 0.289602
I0929 13:16:08.390578  9926 solver.cpp:231] Iteration 4200, loss = 0.0205124
I0929 13:16:08.390640  9926 solver.cpp:247]     Train net output #0: loss = 0.0205122 (* 1 = 0.0205122 loss)
I0929 13:16:08.390653  9926 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I0929 13:16:08.394588  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	7.696	0	48.2957	24	2	0	
I0929 13:16:08.394922  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:16:08.394961  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	24	0	0	
I0929 13:16:08.395790  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):10.25;		(10,10):0;		
I0929 13:16:08.398206  9926 solver.cpp:260]     Total regularization terms: 0.222896 loss+regular. : 0.243408
I0929 13:16:10.091274  9926 solver.cpp:231] Iteration 4300, loss = 0.0994007
I0929 13:16:10.091382  9926 solver.cpp:247]     Train net output #0: loss = 0.0994005 (* 1 = 0.0994005 loss)
I0929 13:16:10.091398  9926 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I0929 13:16:10.097053  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	7.948	0	52.5737	24.8	2.12	0	
I0929 13:16:10.097335  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	
I0929 13:16:10.097365  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	24.8	0	0	
I0929 13:16:10.097934  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):13;		(10,10):0;		
I0929 13:16:10.099992  9926 solver.cpp:260]     Total regularization terms: 0.21698 loss+regular. : 0.316381
I0929 13:16:11.787535  9926 solver.cpp:231] Iteration 4400, loss = 0.0508172
I0929 13:16:11.787596  9926 solver.cpp:247]     Train net output #0: loss = 0.0508169 (* 1 = 0.0508169 loss)
I0929 13:16:11.787606  9926 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I0929 13:16:11.793176  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	8.116	0	55.353	24.4	2.26	0	
I0929 13:16:11.793493  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.125	0	0	0	
I0929 13:16:11.793524  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	24.4	0	0	
I0929 13:16:11.794113  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):14.225;		(10,10):0;		
I0929 13:16:11.796171  9926 solver.cpp:260]     Total regularization terms: 0.212424 loss+regular. : 0.263242
I0929 13:16:13.513238  9926 solver.cpp:348] Iteration 4500, Testing net (#0)
I0929 13:16:14.518613  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9768
I0929 13:16:14.518679  9926 solver.cpp:415]     Test net output #1: loss = 0.071648 (* 1 = 0.071648 loss)
I0929 13:16:14.528710  9926 solver.cpp:231] Iteration 4500, loss = 0.0794173
I0929 13:16:14.528741  9926 solver.cpp:247]     Train net output #0: loss = 0.079417 (* 1 = 0.079417 loss)
I0929 13:16:14.528755  9926 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I0929 13:16:14.533902  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	8.32	0	57.323	24.2	2.18	0	
I0929 13:16:14.534245  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.25	0	0	0	
I0929 13:16:14.534276  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	24.2	0	0	
I0929 13:16:14.534947  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):13.4;		(10,10):0;		
I0929 13:16:14.537119  9926 solver.cpp:260]     Total regularization terms: 0.210371 loss+regular. : 0.289788
I0929 13:16:16.236603  9926 solver.cpp:231] Iteration 4600, loss = 0.0308742
I0929 13:16:16.236891  9926 solver.cpp:247]     Train net output #0: loss = 0.0308739 (* 1 = 0.0308739 loss)
I0929 13:16:16.236933  9926 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I0929 13:16:16.242225  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	8.556	0	59.757	23	2.18	0	
I0929 13:16:16.242847  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	3.75	0	0	0	
I0929 13:16:16.242918  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	23	0	0	
I0929 13:16:16.246335  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):18.475;		(10,10):0;		
I0929 13:16:16.250195  9926 solver.cpp:260]     Total regularization terms: 0.208193 loss+regular. : 0.239067
I0929 13:16:18.048076  9926 solver.cpp:231] Iteration 4700, loss = 0.0707326
I0929 13:16:18.048154  9926 solver.cpp:247]     Train net output #0: loss = 0.0707322 (* 1 = 0.0707322 loss)
I0929 13:16:18.048168  9926 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I0929 13:16:18.051967  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	8.956	0	63.309	23.8	2.16	0	
I0929 13:16:18.052429  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	4.75	0	0	0	
I0929 13:16:18.052477  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	23.8	0	0	
I0929 13:16:18.054188  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):22.95;		(10,10):0;		
I0929 13:16:18.056534  9926 solver.cpp:260]     Total regularization terms: 0.200686 loss+regular. : 0.271419
I0929 13:16:19.807885  9926 solver.cpp:231] Iteration 4800, loss = 0.145314
I0929 13:16:19.807958  9926 solver.cpp:247]     Train net output #0: loss = 0.145314 (* 1 = 0.145314 loss)
I0929 13:16:19.807972  9926 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I0929 13:16:19.811331  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	9.096	0	65.5612	24	2.26	0	
I0929 13:16:19.811813  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	6.25	0	0	0	
I0929 13:16:19.811859  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	24	0	0	
I0929 13:16:19.814054  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):25.55;		(10,10):0;		
I0929 13:16:19.816517  9926 solver.cpp:260]     Total regularization terms: 0.196909 loss+regular. : 0.342223
I0929 13:16:21.636099  9926 solver.cpp:231] Iteration 4900, loss = 0.0620567
I0929 13:16:21.636178  9926 solver.cpp:247]     Train net output #0: loss = 0.0620563 (* 1 = 0.0620563 loss)
I0929 13:16:21.636193  9926 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I0929 13:16:21.639377  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	8.736	0	64.6107	22.6	2.4	0	
I0929 13:16:21.639822  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	5.625	0	0	0	
I0929 13:16:21.639865  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	22.6	0	0	
I0929 13:16:21.641723  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):19.4;		(10,10):0;		
I0929 13:16:21.644234  9926 solver.cpp:260]     Total regularization terms: 0.198877 loss+regular. : 0.260934
I0929 13:16:23.464273  9926 solver.cpp:465] Snapshotting to binary proto file lenet_mjc_iter_5000.caffemodel
I0929 13:16:23.482892  9926 sgd_solver.cpp:655] Snapshotting solver state to binary proto file lenet_mjc_iter_5000.solverstate
I0929 13:16:23.493378  9926 solver.cpp:348] Iteration 5000, Testing net (#0)
I0929 13:16:24.487795  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9801
I0929 13:16:24.487865  9926 solver.cpp:415]     Test net output #1: loss = 0.0608778 (* 1 = 0.0608778 loss)
I0929 13:16:24.497274  9926 solver.cpp:231] Iteration 5000, loss = 0.0702537
I0929 13:16:24.497310  9926 solver.cpp:247]     Train net output #0: loss = 0.0702534 (* 1 = 0.0702534 loss)
I0929 13:16:24.497324  9926 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I0929 13:16:24.503087  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	9.268	0	68.1837	23.8	2.52	0	
I0929 13:16:24.503291  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	8.75	0	0	0	
I0929 13:16:24.503334  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	23.8	0	0	
I0929 13:16:24.504376  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):30.575;		(10,10):0;		
I0929 13:16:24.506515  9926 solver.cpp:260]     Total regularization terms: 0.194468 loss+regular. : 0.264722
I0929 13:16:26.279667  9926 solver.cpp:231] Iteration 5100, loss = 0.138568
I0929 13:16:26.279731  9926 solver.cpp:247]     Train net output #0: loss = 0.138568 (* 1 = 0.138568 loss)
I0929 13:16:26.279744  9926 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I0929 13:16:26.283929  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0	0	9.684	0	70.8235	24.2	2.58	0	
I0929 13:16:26.284587  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	10.75	0	0	0	
I0929 13:16:26.284649  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	24.2	0	0	
I0929 13:16:26.287179  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):37.575;		(10,10):0;		
I0929 13:16:26.290096  9926 solver.cpp:260]     Total regularization terms: 0.189679 loss+regular. : 0.328247
I0929 13:16:28.091295  9926 solver.cpp:231] Iteration 5200, loss = 0.0541936
I0929 13:16:28.091398  9926 solver.cpp:247]     Train net output #0: loss = 0.0541932 (* 1 = 0.0541932 loss)
I0929 13:16:28.091414  9926 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I0929 13:16:28.095371  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	9.672	0	71.1875	24.2	2.54	0	
I0929 13:16:28.095932  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	9.5	0	0	0	
I0929 13:16:28.095973  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	24.2	0	0	
I0929 13:16:28.097543  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):31;		(10,10):0;		
I0929 13:16:28.099980  9926 solver.cpp:260]     Total regularization terms: 0.188483 loss+regular. : 0.242676
I0929 13:16:29.795892  9926 solver.cpp:231] Iteration 5300, loss = 0.0418364
I0929 13:16:29.795964  9926 solver.cpp:247]     Train net output #0: loss = 0.0418361 (* 1 = 0.0418361 loss)
I0929 13:16:29.795975  9926 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I0929 13:16:29.801517  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.4	0	9.976	0	72.2425	25.2	2.56	0	
I0929 13:16:29.802000  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	10.375	0	0	0	
I0929 13:16:29.802031  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	25.2	0	0	
I0929 13:16:29.803097  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0;		(10,10):35.725;		(10,10):0;		
I0929 13:16:29.805233  9926 solver.cpp:260]     Total regularization terms: 0.185406 loss+regular. : 0.227243
I0929 13:16:31.616066  9926 solver.cpp:231] Iteration 5400, loss = 0.0772575
I0929 13:16:31.616144  9926 solver.cpp:247]     Train net output #0: loss = 0.0772571 (* 1 = 0.0772571 loss)
I0929 13:16:31.616158  9926 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I0929 13:16:31.619658  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	10.444	0	73.2265	25	2.64	0	
I0929 13:16:31.620324  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	11.75	0	0	0	
I0929 13:16:31.620378  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0.2	25	0	0	
I0929 13:16:31.622742  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0.5;		(10,10):36.5;		(10,10):0;		
I0929 13:16:31.624959  9926 solver.cpp:260]     Total regularization terms: 0.1839 loss+regular. : 0.261157
I0929 13:16:33.430411  9926 solver.cpp:348] Iteration 5500, Testing net (#0)
I0929 13:16:34.415691  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9825
I0929 13:16:34.415786  9926 solver.cpp:415]     Test net output #1: loss = 0.0586916 (* 1 = 0.0586916 loss)
I0929 13:16:34.425246  9926 solver.cpp:231] Iteration 5500, loss = 0.0335484
I0929 13:16:34.425269  9926 solver.cpp:247]     Train net output #0: loss = 0.033548 (* 1 = 0.033548 loss)
I0929 13:16:34.425282  9926 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I0929 13:16:34.430981  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	10.72	0	72.8788	24.8	2.56	0	
I0929 13:16:34.431458  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	8.125	0	0	0	
I0929 13:16:34.431536  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0.4	24.8	0	0	
I0929 13:16:34.432597  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):0.5;		(10,10):34.25;		(10,10):0;		
I0929 13:16:34.434782  9926 solver.cpp:260]     Total regularization terms: 0.184423 loss+regular. : 0.217971
I0929 13:16:36.123040  9926 solver.cpp:231] Iteration 5600, loss = 0.0153717
I0929 13:16:36.123126  9926 solver.cpp:247]     Train net output #0: loss = 0.0153713 (* 1 = 0.0153713 loss)
I0929 13:16:36.123136  9926 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I0929 13:16:36.128921  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	11.404	0	75.609	26.2	2.66	0	
I0929 13:16:36.129433  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	13.375	0	0	0	
I0929 13:16:36.129477  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	1	26.2	0	0	
I0929 13:16:36.130736  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):1;		(10,10):47.8;		(10,10):0;		
I0929 13:16:36.132777  9926 solver.cpp:260]     Total regularization terms: 0.180101 loss+regular. : 0.195473
I0929 13:16:37.932636  9926 solver.cpp:231] Iteration 5700, loss = 0.0397763
I0929 13:16:37.932701  9926 solver.cpp:247]     Train net output #0: loss = 0.0397759 (* 1 = 0.0397759 loss)
I0929 13:16:37.932715  9926 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I0929 13:16:37.936568  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	11.652	0	76.598	26.6	2.66	0	
I0929 13:16:37.937144  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	14.75	0	0	0	
I0929 13:16:37.937214  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	2	26.6	0	0	
I0929 13:16:37.940129  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):1;		(10,10):45.95;		(10,10):0;		
I0929 13:16:37.942378  9926 solver.cpp:260]     Total regularization terms: 0.175676 loss+regular. : 0.215452
I0929 13:16:39.696308  9926 solver.cpp:231] Iteration 5800, loss = 0.0585017
I0929 13:16:39.696424  9926 solver.cpp:247]     Train net output #0: loss = 0.0585013 (* 1 = 0.0585013 loss)
I0929 13:16:39.696444  9926 sgd_solver.cpp:106] Iteration 5800, lr = 0.0070959
I0929 13:16:39.700294  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	11.268	0	74.5755	24.8	2.64	0	
I0929 13:16:39.700840  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	9.625	0	0	0	
I0929 13:16:39.700935  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	3.6	24.8	0	0	
I0929 13:16:39.703063  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):1;		(10,10):29.2;		(10,10):0;		
I0929 13:16:39.705348  9926 solver.cpp:260]     Total regularization terms: 0.176387 loss+regular. : 0.234888
I0929 13:16:41.455536  9926 solver.cpp:231] Iteration 5900, loss = 0.0451629
I0929 13:16:41.455606  9926 solver.cpp:247]     Train net output #0: loss = 0.0451625 (* 1 = 0.0451625 loss)
I0929 13:16:41.455649  9926 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I0929 13:16:41.459712  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	12.132	0	76.9638	25.2	2.72	0	
I0929 13:16:41.460351  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	13	0	0	0	
I0929 13:16:41.460474  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	5	25.2	0	0	
I0929 13:16:41.463150  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):1;		(10,10):41.825;		(10,10):0;		
I0929 13:16:41.465456  9926 solver.cpp:260]     Total regularization terms: 0.175277 loss+regular. : 0.220439
I0929 13:16:43.254278  9926 solver.cpp:348] Iteration 6000, Testing net (#0)
I0929 13:16:44.304059  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9862
I0929 13:16:44.304133  9926 solver.cpp:415]     Test net output #1: loss = 0.0470365 (* 1 = 0.0470365 loss)
I0929 13:16:44.314812  9926 solver.cpp:231] Iteration 6000, loss = 0.0245965
I0929 13:16:44.314852  9926 solver.cpp:247]     Train net output #0: loss = 0.0245961 (* 1 = 0.0245961 loss)
I0929 13:16:44.314867  9926 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I0929 13:16:44.319550  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	12.7	0	79.0218	26.4	2.74	0	
I0929 13:16:44.320143  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	18.625	0	0	0	
I0929 13:16:44.320233  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	6.6	26.4	0	0	
I0929 13:16:44.321907  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):1;		(10,10):53.55;		(10,10):0;		
I0929 13:16:44.324604  9926 solver.cpp:260]     Total regularization terms: 0.172012 loss+regular. : 0.196609
I0929 13:16:46.180040  9926 solver.cpp:231] Iteration 6100, loss = 0.0206949
I0929 13:16:46.180125  9926 solver.cpp:247]     Train net output #0: loss = 0.0206945 (* 1 = 0.0206945 loss)
I0929 13:16:46.180143  9926 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I0929 13:16:46.183233  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	13.212	0	79.1773	25.8	2.76	0	
I0929 13:16:46.183877  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	14.625	0	0	0	
I0929 13:16:46.184075  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	7.8	25.8	0	0	
I0929 13:16:46.187741  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):1.5;		(10,10):48.275;		(10,10):0;		
I0929 13:16:46.190243  9926 solver.cpp:260]     Total regularization terms: 0.170149 loss+regular. : 0.190844
I0929 13:16:47.991365  9926 solver.cpp:231] Iteration 6200, loss = 0.0597564
I0929 13:16:47.991552  9926 solver.cpp:247]     Train net output #0: loss = 0.059756 (* 1 = 0.059756 loss)
I0929 13:16:47.991566  9926 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I0929 13:16:47.995065  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	13.776	0	79.8242	26.8	2.82	0	
I0929 13:16:47.995715  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	17.375	0	0	0	
I0929 13:16:47.995889  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	9.2	26.8	0	0	
I0929 13:16:47.999059  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):2.5;		(10,10):49.1;		(10,10):0;		
I0929 13:16:48.001368  9926 solver.cpp:260]     Total regularization terms: 0.168166 loss+regular. : 0.227922
I0929 13:16:49.767127  9926 solver.cpp:231] Iteration 6300, loss = 0.0543714
I0929 13:16:49.767195  9926 solver.cpp:247]     Train net output #0: loss = 0.054371 (* 1 = 0.054371 loss)
I0929 13:16:49.767210  9926 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I0929 13:16:49.771004  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	14.24	0	79.982	26.6	2.82	0	
I0929 13:16:49.771689  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	19.125	0	0	0	
I0929 13:16:49.771875  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	11	26.6	0	0	
I0929 13:16:49.775146  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):2.5;		(10,10):49.3;		(10,10):0;		
I0929 13:16:49.777457  9926 solver.cpp:260]     Total regularization terms: 0.16676 loss+regular. : 0.221131
I0929 13:16:51.566345  9926 solver.cpp:231] Iteration 6400, loss = 0.0776238
I0929 13:16:51.566401  9926 solver.cpp:247]     Train net output #0: loss = 0.0776234 (* 1 = 0.0776234 loss)
I0929 13:16:51.566413  9926 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I0929 13:16:51.570332  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	14.808	0	80.0983	27	2.84	0	
I0929 13:16:51.571002  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	17.625	0	0	0	
I0929 13:16:51.571231  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	11.4	27	0	0	
I0929 13:16:51.574733  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):2.5;		(10,10):48.7;		(10,10):0;		
I0929 13:16:51.577363  9926 solver.cpp:260]     Total regularization terms: 0.167425 loss+regular. : 0.245049
I0929 13:16:53.363184  9926 solver.cpp:348] Iteration 6500, Testing net (#0)
I0929 13:16:54.429181  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9826
I0929 13:16:54.429240  9926 solver.cpp:415]     Test net output #1: loss = 0.0531487 (* 1 = 0.0531487 loss)
I0929 13:16:54.442286  9926 solver.cpp:231] Iteration 6500, loss = 0.0692991
I0929 13:16:54.442339  9926 solver.cpp:247]     Train net output #0: loss = 0.0692986 (* 1 = 0.0692986 loss)
I0929 13:16:54.442354  9926 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I0929 13:16:54.445576  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.2	0	15.836	0	81.0853	27	2.9	0	
I0929 13:16:54.446211  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	18.375	0	0	0	
I0929 13:16:54.446400  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	11.2	27	0	0	
I0929 13:16:54.450018  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):3.5;		(10,10):53;		(10,10):0;		
I0929 13:16:54.452616  9926 solver.cpp:260]     Total regularization terms: 0.165134 loss+regular. : 0.234433
I0929 13:16:56.254746  9926 solver.cpp:231] Iteration 6600, loss = 0.0687379
I0929 13:16:56.254809  9926 solver.cpp:247]     Train net output #0: loss = 0.0687375 (* 1 = 0.0687375 loss)
I0929 13:16:56.254823  9926 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I0929 13:16:56.258345  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	18.02	0	81.9115	27.8	3	0	
I0929 13:16:56.259021  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	22.625	0	0	0	
I0929 13:16:56.259199  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	12.4	27.8	0	0	
I0929 13:16:56.263021  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):5.5;		(10,10):55.175;		(10,10):0;		
I0929 13:16:56.265396  9926 solver.cpp:260]     Total regularization terms: 0.162098 loss+regular. : 0.230836
I0929 13:16:58.061189  9926 solver.cpp:231] Iteration 6700, loss = 0.0720027
I0929 13:16:58.061249  9926 solver.cpp:247]     Train net output #0: loss = 0.0720023 (* 1 = 0.0720023 loss)
I0929 13:16:58.061262  9926 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I0929 13:16:58.064908  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.4	0	19.024	0	82.6345	28	3	0	
I0929 13:16:58.065714  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	23.25	0	0	0	
I0929 13:16:58.065937  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	13.2	28	0	0	
I0929 13:16:58.069563  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):7.5;		(10,10):56.975;		(10,10):0;		
I0929 13:16:58.071794  9926 solver.cpp:260]     Total regularization terms: 0.160144 loss+regular. : 0.232146
I0929 13:16:59.878036  9926 solver.cpp:231] Iteration 6800, loss = 0.0506058
I0929 13:16:59.878099  9926 solver.cpp:247]     Train net output #0: loss = 0.0506054 (* 1 = 0.0506054 loss)
I0929 13:16:59.878135  9926 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I0929 13:16:59.881767  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.4	0	19.228	0	82.5595	27.4	3	0	
I0929 13:16:59.882465  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	20.375	0	0	0	
I0929 13:16:59.882658  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	13	27.4	0	0	
I0929 13:16:59.886461  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):7.5;		(10,10):58;		(10,10):0;		
I0929 13:16:59.888911  9926 solver.cpp:260]     Total regularization terms: 0.16107 loss+regular. : 0.211676
I0929 13:17:01.685319  9926 solver.cpp:231] Iteration 6900, loss = 0.0327446
I0929 13:17:01.685374  9926 solver.cpp:247]     Train net output #0: loss = 0.0327442 (* 1 = 0.0327442 loss)
I0929 13:17:01.685386  9926 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I0929 13:17:01.688766  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.6	0	20.188	0	83.5535	28.6	3	0	
I0929 13:17:01.689488  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	26	0	0	0	
I0929 13:17:01.689683  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	13.4	28.6	0	0	
I0929 13:17:01.693473  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):9;		(10,10):61.075;		(10,10):0;		
I0929 13:17:01.696151  9926 solver.cpp:260]     Total regularization terms: 0.159046 loss+regular. : 0.191791
I0929 13:17:03.498536  9926 solver.cpp:348] Iteration 7000, Testing net (#0)
I0929 13:17:04.497216  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9808
I0929 13:17:04.497285  9926 solver.cpp:415]     Test net output #1: loss = 0.0605618 (* 1 = 0.0605618 loss)
I0929 13:17:04.507048  9926 solver.cpp:231] Iteration 7000, loss = 0.066288
I0929 13:17:04.507079  9926 solver.cpp:247]     Train net output #0: loss = 0.0662875 (* 1 = 0.0662875 loss)
I0929 13:17:04.507091  9926 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I0929 13:17:04.512604  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.4	0	21.12	0	84.0322	28.2	3.06	0	
I0929 13:17:04.513213  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	25.375	0	0	0	
I0929 13:17:04.513305  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	13.8	28.2	0	0	
I0929 13:17:04.514871  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):9;		(10,10):59.225;		(10,10):0;		
I0929 13:17:04.516922  9926 solver.cpp:260]     Total regularization terms: 0.156657 loss+regular. : 0.222945
I0929 13:17:06.325825  9926 solver.cpp:231] Iteration 7100, loss = 0.129269
I0929 13:17:06.325887  9926 solver.cpp:247]     Train net output #0: loss = 0.129268 (* 1 = 0.129268 loss)
I0929 13:17:06.325901  9926 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I0929 13:17:06.329754  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.6	0	21.948	0	84.7615	28.8	3.08	0	
I0929 13:17:06.330499  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	27.625	0	0	0	
I0929 13:17:06.330730  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	14.4	28.8	0	0	
I0929 13:17:06.334611  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):10.5;		(10,10):62.425;		(10,10):0;		
I0929 13:17:06.336901  9926 solver.cpp:260]     Total regularization terms: 0.155606 loss+regular. : 0.284874
I0929 13:17:08.094449  9926 solver.cpp:231] Iteration 7200, loss = 0.0196998
I0929 13:17:08.094516  9926 solver.cpp:247]     Train net output #0: loss = 0.0196993 (* 1 = 0.0196993 loss)
I0929 13:17:08.094529  9926 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I0929 13:17:08.098523  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.4	0	22.568	0	84.6257	28.8	3.08	0	
I0929 13:17:08.099261  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	27	0	0	0	
I0929 13:17:08.099508  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	14.8	28.8	0	0	
I0929 13:17:08.103238  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):10.5;		(10,10):62.15;		(10,10):0;		
I0929 13:17:08.105525  9926 solver.cpp:260]     Total regularization terms: 0.153937 loss+regular. : 0.173636
I0929 13:17:09.860437  9926 solver.cpp:231] Iteration 7300, loss = 0.0927751
I0929 13:17:09.860509  9926 solver.cpp:247]     Train net output #0: loss = 0.0927747 (* 1 = 0.0927747 loss)
I0929 13:17:09.860523  9926 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I0929 13:17:09.864388  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.6	0	24.088	0	84.9145	28.6	3.08	0	
I0929 13:17:09.865185  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	25.375	0	0	0	
I0929 13:17:09.865456  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	15	28.6	0	0	
I0929 13:17:09.869226  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):11;		(10,10):60.975;		(10,10):0;		
I0929 13:17:09.871578  9926 solver.cpp:260]     Total regularization terms: 0.153548 loss+regular. : 0.246323
I0929 13:17:11.671421  9926 solver.cpp:231] Iteration 7400, loss = 0.0740473
I0929 13:17:11.671486  9926 solver.cpp:247]     Train net output #0: loss = 0.0740469 (* 1 = 0.0740469 loss)
I0929 13:17:11.671500  9926 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I0929 13:17:11.675552  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.6	0	26.216	0	84.9388	29.2	3.08	0	
I0929 13:17:11.676293  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	26.25	0	0	0	
I0929 13:17:11.676547  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	17.8	29.2	0	0	
I0929 13:17:11.680084  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):11.5;		(10,10):61.225;		(10,10):0;		
I0929 13:17:11.682346  9926 solver.cpp:260]     Total regularization terms: 0.153041 loss+regular. : 0.227088
I0929 13:17:13.438448  9926 solver.cpp:348] Iteration 7500, Testing net (#0)
I0929 13:17:14.453938  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9825
I0929 13:17:14.453999  9926 solver.cpp:415]     Test net output #1: loss = 0.0554839 (* 1 = 0.0554839 loss)
I0929 13:17:14.466763  9926 solver.cpp:231] Iteration 7500, loss = 0.025104
I0929 13:17:14.466794  9926 solver.cpp:247]     Train net output #0: loss = 0.0251036 (* 1 = 0.0251036 loss)
I0929 13:17:14.466810  9926 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I0929 13:17:14.470257  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.4	0	27.568	0	85.8702	29.2	3.04	0	
I0929 13:17:14.471132  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	28.75	0	0	0	
I0929 13:17:14.471465  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	18.6	29.2	0	0	
I0929 13:17:14.475981  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):13.5;		(10,10):63.9;		(10,10):0;		
I0929 13:17:14.478468  9926 solver.cpp:260]     Total regularization terms: 0.150463 loss+regular. : 0.175567
I0929 13:17:16.260223  9926 solver.cpp:231] Iteration 7600, loss = 0.0979793
I0929 13:17:16.260288  9926 solver.cpp:247]     Train net output #0: loss = 0.0979789 (* 1 = 0.0979789 loss)
I0929 13:17:16.260301  9926 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I0929 13:17:16.264310  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.6	0	29.196	0	86.222	29.8	3.12	0	
I0929 13:17:16.265138  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0.2	0	30.375	0	0	0	
I0929 13:17:16.265450  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	19.2	29.8	0	0	
I0929 13:17:16.269301  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):15;		(10,10):64.65;		(10,10):0;		
I0929 13:17:16.271625  9926 solver.cpp:260]     Total regularization terms: 0.148963 loss+regular. : 0.246943
I0929 13:17:18.093649  9926 solver.cpp:231] Iteration 7700, loss = 0.0437
I0929 13:17:18.093879  9926 solver.cpp:247]     Train net output #0: loss = 0.0436996 (* 1 = 0.0436996 loss)
I0929 13:17:18.093895  9926 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I0929 13:17:18.096776  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.6	0	29.4	0	85.6397	28.8	3.1	0	
I0929 13:17:18.097564  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0.2	0	26.25	0	0	0	
I0929 13:17:18.097877  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	18.6	28.8	0	0	
I0929 13:17:18.102092  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):12.5;		(10,10):62.125;		(10,10):0;		
I0929 13:17:18.104722  9926 solver.cpp:260]     Total regularization terms: 0.149165 loss+regular. : 0.192865
I0929 13:17:19.921922  9926 solver.cpp:231] Iteration 7800, loss = 0.105244
I0929 13:17:19.922045  9926 solver.cpp:247]     Train net output #0: loss = 0.105244 (* 1 = 0.105244 loss)
I0929 13:17:19.922061  9926 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I0929 13:17:19.925690  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.6	0	31.052	0	86.611	28.8	3.1	0	
I0929 13:17:19.926494  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0.2	0	33.25	0	0	0	
I0929 13:17:19.926786  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	21.2	28.8	0	0	
I0929 13:17:19.931293  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):19.5;		(10,10):66.375;		(10,10):0;		
I0929 13:17:19.933565  9926 solver.cpp:260]     Total regularization terms: 0.148484 loss+regular. : 0.253728
I0929 13:17:21.748464  9926 solver.cpp:231] Iteration 7900, loss = 0.0225644
I0929 13:17:21.765383  9926 solver.cpp:247]     Train net output #0: loss = 0.022564 (* 1 = 0.022564 loss)
I0929 13:17:21.765420  9926 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I0929 13:17:21.766044  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.6	0	31.768	0	87.5518	29.6	3.18	0	
I0929 13:17:21.767714  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0.2	0	35.625	0	0	0	
I0929 13:17:21.768463  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	21.8	29.6	0	0	
I0929 13:17:21.778318  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):20;		(10,10):72.2;		(10,10):0;		
I0929 13:17:21.781986  9926 solver.cpp:260]     Total regularization terms: 0.146104 loss+regular. : 0.168669
I0929 13:17:23.549716  9926 solver.cpp:348] Iteration 8000, Testing net (#0)
I0929 13:17:24.633477  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9859
I0929 13:17:24.633534  9926 solver.cpp:415]     Test net output #1: loss = 0.0476168 (* 1 = 0.0476168 loss)
I0929 13:17:24.646371  9926 solver.cpp:231] Iteration 8000, loss = 0.0555116
I0929 13:17:24.646445  9926 solver.cpp:247]     Train net output #0: loss = 0.0555112 (* 1 = 0.0555112 loss)
I0929 13:17:24.646468  9926 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I0929 13:17:24.649459  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	32.184	0	87.583	29.6	3.12	0	
I0929 13:17:24.650408  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0.2	0	35.5	0	0	0	
I0929 13:17:24.650648  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	22.8	29.6	0	0	
I0929 13:17:24.654486  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):19;		(10,10):70;		(10,10):0;		
I0929 13:17:24.657282  9926 solver.cpp:260]     Total regularization terms: 0.145349 loss+regular. : 0.200861
I0929 13:17:26.463701  9926 solver.cpp:231] Iteration 8100, loss = 0.048047
I0929 13:17:26.463757  9926 solver.cpp:247]     Train net output #0: loss = 0.0480466 (* 1 = 0.0480466 loss)
I0929 13:17:26.463783  9926 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I0929 13:17:26.467754  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	32.86	0	87.6168	29.6	3.14	0	
I0929 13:17:26.468650  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0.2	0	34.875	0	0	0	
I0929 13:17:26.469007  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	23	29.6	0	0	
I0929 13:17:26.473001  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):20;		(10,10):67.575;		(10,10):0;		
I0929 13:17:26.475286  9926 solver.cpp:260]     Total regularization terms: 0.144285 loss+regular. : 0.192332
I0929 13:17:28.270674  9926 solver.cpp:231] Iteration 8200, loss = 0.0552268
I0929 13:17:28.270735  9926 solver.cpp:247]     Train net output #0: loss = 0.0552264 (* 1 = 0.0552264 loss)
I0929 13:17:28.270758  9926 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I0929 13:17:28.274801  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	33.316	0	87.8925	29.4	3.18	0	
I0929 13:17:28.275701  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0.2	0	34.125	0	0	0	
I0929 13:17:28.276121  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	25.4	29.4	0	0	
I0929 13:17:28.280129  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):19;		(10,10):70.05;		(10,10):0;		
I0929 13:17:28.282418  9926 solver.cpp:260]     Total regularization terms: 0.14339 loss+regular. : 0.198616
I0929 13:17:30.064270  9926 solver.cpp:231] Iteration 8300, loss = 0.14712
I0929 13:17:30.064333  9926 solver.cpp:247]     Train net output #0: loss = 0.147119 (* 1 = 0.147119 loss)
I0929 13:17:30.064378  9926 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I0929 13:17:30.068313  9926 sgd_solver.cpp:120]     Element Sparsity %: 
1	0	33.716	0	87.8832	29.8	3.28	0	
I0929 13:17:30.069195  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0.2	0	35	0	0	0	
I0929 13:17:30.069571  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	25	29.8	0	0	
I0929 13:17:30.073662  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):19.5;		(10,10):70.8;		(10,10):0;		
I0929 13:17:30.075964  9926 solver.cpp:260]     Total regularization terms: 0.143568 loss+regular. : 0.290688
I0929 13:17:31.843379  9926 solver.cpp:231] Iteration 8400, loss = 0.0997437
I0929 13:17:31.843441  9926 solver.cpp:247]     Train net output #0: loss = 0.0997433 (* 1 = 0.0997433 loss)
I0929 13:17:31.843466  9926 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I0929 13:17:31.847514  9926 sgd_solver.cpp:120]     Element Sparsity %: 
1	0	34.508	0	88.438	30.2	3.38	0	
I0929 13:17:31.848367  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0.2	0	37.375	0	0	0	
I0929 13:17:31.848803  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	28.8	30.2	0	0	
I0929 13:17:31.853039  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):22;		(10,10):73.8;		(10,10):0;		
I0929 13:17:31.855299  9926 solver.cpp:260]     Total regularization terms: 0.141995 loss+regular. : 0.241739
I0929 13:17:33.625282  9926 solver.cpp:348] Iteration 8500, Testing net (#0)
I0929 13:17:34.692029  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9838
I0929 13:17:34.692108  9926 solver.cpp:415]     Test net output #1: loss = 0.0513607 (* 1 = 0.0513607 loss)
I0929 13:17:34.704473  9926 solver.cpp:231] Iteration 8500, loss = 0.0480358
I0929 13:17:34.704515  9926 solver.cpp:247]     Train net output #0: loss = 0.0480353 (* 1 = 0.0480353 loss)
I0929 13:17:34.704532  9926 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I0929 13:17:34.708282  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	35.156	0	88.7747	30.4	3.22	0	
I0929 13:17:34.709238  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0.2	0	39.375	0	0	0	
I0929 13:17:34.709717  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	28.8	30.4	0	0	
I0929 13:17:34.714355  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):23;		(10,10):75.8;		(10,10):0;		
I0929 13:17:34.716789  9926 solver.cpp:260]     Total regularization terms: 0.13983 loss+regular. : 0.187865
I0929 13:17:36.518038  9926 solver.cpp:231] Iteration 8600, loss = 0.00471304
I0929 13:17:36.518126  9926 solver.cpp:247]     Train net output #0: loss = 0.00471261 (* 1 = 0.00471261 loss)
I0929 13:17:36.518139  9926 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I0929 13:17:36.521795  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	34.56	0	88.1267	29.4	3.24	0	
I0929 13:17:36.522718  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0.4	0	35.125	0	0	0	
I0929 13:17:36.523208  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	29	29.4	0	0	
I0929 13:17:36.527505  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):15.5;		(10,10):68.1;		(10,10):0;		
I0929 13:17:36.529922  9926 solver.cpp:260]     Total regularization terms: 0.139808 loss+regular. : 0.144521
I0929 13:17:38.326498  9926 solver.cpp:231] Iteration 8700, loss = 0.0205446
I0929 13:17:38.326565  9926 solver.cpp:247]     Train net output #0: loss = 0.0205442 (* 1 = 0.0205442 loss)
I0929 13:17:38.326578  9926 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I0929 13:17:38.330381  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	36.532	0	88.884	30.6	3.4	0	
I0929 13:17:38.331254  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0.4	0	37.625	0	0	0	
I0929 13:17:38.331712  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	31.2	30.6	0	0	
I0929 13:17:38.336236  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):23;		(10,10):75.25;		(10,10):0;		
I0929 13:17:38.338498  9926 solver.cpp:260]     Total regularization terms: 0.139632 loss+regular. : 0.160177
I0929 13:17:40.113775  9926 solver.cpp:231] Iteration 8800, loss = 0.0135578
I0929 13:17:40.113840  9926 solver.cpp:247]     Train net output #0: loss = 0.0135573 (* 1 = 0.0135573 loss)
I0929 13:17:40.113853  9926 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I0929 13:17:40.117764  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	37.76	0	89.479	31.2	3.44	0	
I0929 13:17:40.118705  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0.6	0	44.25	0	0	0	
I0929 13:17:40.119215  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	34	31.2	0	0	
I0929 13:17:40.123661  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):24;		(10,10):77.95;		(10,10):0;		
I0929 13:17:40.125977  9926 solver.cpp:260]     Total regularization terms: 0.13831 loss+regular. : 0.151867
I0929 13:17:41.913133  9926 solver.cpp:231] Iteration 8900, loss = 0.00795557
I0929 13:17:41.913202  9926 solver.cpp:247]     Train net output #0: loss = 0.00795512 (* 1 = 0.00795512 loss)
I0929 13:17:41.913214  9926 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I0929 13:17:41.917121  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	39.104	0	89.5145	31	3.32	0	
I0929 13:17:41.918131  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	3.2	0	41.5	0	0	0	
I0929 13:17:41.918715  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	37.2	31	0	0	
I0929 13:17:41.923570  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):24;		(10,10):75.225;		(10,10):0;		
I0929 13:17:41.925843  9926 solver.cpp:260]     Total regularization terms: 0.137072 loss+regular. : 0.145028
I0929 13:17:43.729365  9926 solver.cpp:348] Iteration 9000, Testing net (#0)
I0929 13:17:44.831795  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9842
I0929 13:17:44.831887  9926 solver.cpp:415]     Test net output #1: loss = 0.0482999 (* 1 = 0.0482999 loss)
I0929 13:17:44.843863  9926 solver.cpp:231] Iteration 9000, loss = 0.0865247
I0929 13:17:44.843891  9926 solver.cpp:247]     Train net output #0: loss = 0.0865243 (* 1 = 0.0865243 loss)
I0929 13:17:44.843919  9926 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I0929 13:17:44.847908  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.6	0	40.36	0	89.7678	31.6	3.38	0	
I0929 13:17:44.848870  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	5	0	45.25	0	0	0	
I0929 13:17:44.849460  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	40.2	31.6	0	0	
I0929 13:17:44.853919  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):27;		(10,10):77.725;		(10,10):0;		
I0929 13:17:44.856256  9926 solver.cpp:260]     Total regularization terms: 0.136205 loss+regular. : 0.22273
I0929 13:17:46.631002  9926 solver.cpp:231] Iteration 9100, loss = 0.076993
I0929 13:17:46.631073  9926 solver.cpp:247]     Train net output #0: loss = 0.0769926 (* 1 = 0.0769926 loss)
I0929 13:17:46.631086  9926 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I0929 13:17:46.635152  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	41.72	0	89.969	31.8	3.4	0	
I0929 13:17:46.636117  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	5.2	0	46.875	0	0	0	
I0929 13:17:46.636648  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	41.6	31.8	0	0	
I0929 13:17:46.640986  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):26.5;		(10,10):78.2;		(10,10):0;		
I0929 13:17:46.643241  9926 solver.cpp:260]     Total regularization terms: 0.13517 loss+regular. : 0.212163
I0929 13:17:48.410981  9926 solver.cpp:231] Iteration 9200, loss = 0.0280928
I0929 13:17:48.411160  9926 solver.cpp:247]     Train net output #0: loss = 0.0280924 (* 1 = 0.0280924 loss)
I0929 13:17:48.411175  9926 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I0929 13:17:48.415225  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.6	0	42.436	0	89.8345	31.4	3.5	0	
I0929 13:17:48.416153  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	5.2	0	44.75	0	0	0	
I0929 13:17:48.416721  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	39.4	31.4	0	0	
I0929 13:17:48.421139  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):27;		(10,10):76.45;		(10,10):0;		
I0929 13:17:48.423449  9926 solver.cpp:260]     Total regularization terms: 0.135424 loss+regular. : 0.163516
I0929 13:17:50.205529  9926 solver.cpp:231] Iteration 9300, loss = 0.019397
I0929 13:17:50.205587  9926 solver.cpp:247]     Train net output #0: loss = 0.0193966 (* 1 = 0.0193966 loss)
I0929 13:17:50.205612  9926 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I0929 13:17:50.209542  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	43.804	0	90.0823	31.4	3.66	0	
I0929 13:17:50.210491  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	5.4	0	46	0	0	0	
I0929 13:17:50.211074  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	43.8	31.4	0	0	
I0929 13:17:50.215646  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):29.5;		(10,10):78.575;		(10,10):0;		
I0929 13:17:50.217963  9926 solver.cpp:260]     Total regularization terms: 0.134599 loss+regular. : 0.153996
I0929 13:17:52.027848  9926 solver.cpp:231] Iteration 9400, loss = 0.0843853
I0929 13:17:52.027901  9926 solver.cpp:247]     Train net output #0: loss = 0.0843849 (* 1 = 0.0843849 loss)
I0929 13:17:52.027914  9926 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I0929 13:17:52.032050  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	44.244	0	90.1787	31.8	3.82	0	
I0929 13:17:52.032928  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	6.4	0	47	0	0	0	
I0929 13:17:52.033453  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	43.4	31.8	0	0	
I0929 13:17:52.037896  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):30;		(10,10):77.725;		(10,10):0;		
I0929 13:17:52.040223  9926 solver.cpp:260]     Total regularization terms: 0.13321 loss+regular. : 0.217595
I0929 13:17:53.816522  9926 solver.cpp:348] Iteration 9500, Testing net (#0)
I0929 13:17:54.818410  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9846
I0929 13:17:54.818466  9926 solver.cpp:415]     Test net output #1: loss = 0.049564 (* 1 = 0.049564 loss)
I0929 13:17:54.827961  9926 solver.cpp:231] Iteration 9500, loss = 0.0127632
I0929 13:17:54.827991  9926 solver.cpp:247]     Train net output #0: loss = 0.0127627 (* 1 = 0.0127627 loss)
I0929 13:17:54.828002  9926 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I0929 13:17:54.833780  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	44.976	0	90.6058	32.2	7.36	0	
I0929 13:17:54.834512  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	10	0	47.75	0	4	0	
I0929 13:17:54.834709  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	45.8	32.2	0	0	
I0929 13:17:54.836709  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):31;		(10,10):80.4;		(10,10):4;		
I0929 13:17:54.838863  9926 solver.cpp:260]     Total regularization terms: 0.132201 loss+regular. : 0.144964
I0929 13:17:56.635299  9926 solver.cpp:231] Iteration 9600, loss = 0.0141337
I0929 13:17:56.635380  9926 solver.cpp:247]     Train net output #0: loss = 0.0141333 (* 1 = 0.0141333 loss)
I0929 13:17:56.635393  9926 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I0929 13:17:56.639375  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	45.38	0	90.3292	31.8	7.44	0	
I0929 13:17:56.640346  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	9	0	46.375	0	4	0	
I0929 13:17:56.640957  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	45	31.8	0	0	
I0929 13:17:56.645344  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):30;		(10,10):78.05;		(10,10):4;		
I0929 13:17:56.647610  9926 solver.cpp:260]     Total regularization terms: 0.132746 loss+regular. : 0.14688
I0929 13:17:58.414575  9926 solver.cpp:231] Iteration 9700, loss = 0.0248112
I0929 13:17:58.414639  9926 solver.cpp:247]     Train net output #0: loss = 0.0248107 (* 1 = 0.0248107 loss)
I0929 13:17:58.414651  9926 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I0929 13:17:58.418772  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	46.744	0	90.7568	32.2	7.66	0	
I0929 13:17:58.419761  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	10	0	49.75	0	4	0	
I0929 13:17:58.420379  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	10	0	46.8	32.2	0	0	
I0929 13:17:58.424950  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):34.5;		(10,10):81.175;		(10,10):4;		
I0929 13:17:58.427177  9926 solver.cpp:260]     Total regularization terms: 0.131785 loss+regular. : 0.156596
I0929 13:18:00.189132  9926 solver.cpp:231] Iteration 9800, loss = 0.096436
I0929 13:18:00.189199  9926 solver.cpp:247]     Train net output #0: loss = 0.0964355 (* 1 = 0.0964355 loss)
I0929 13:18:00.189213  9926 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I0929 13:18:00.193377  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.6	0	47.176	0	90.8928	32.8	9.46	0	
I0929 13:18:00.194293  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	10	0	48.875	0	6	0	
I0929 13:18:00.194905  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	10	0	48	32.8	0	0	
I0929 13:18:00.199460  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):33.5;		(10,10):79.55;		(10,10):6;		
I0929 13:18:00.201740  9926 solver.cpp:260]     Total regularization terms: 0.130653 loss+regular. : 0.227089
I0929 13:18:01.975487  9926 solver.cpp:231] Iteration 9900, loss = 0.0189685
I0929 13:18:01.975558  9926 solver.cpp:247]     Train net output #0: loss = 0.0189681 (* 1 = 0.0189681 loss)
I0929 13:18:01.975569  9926 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I0929 13:18:01.979543  9926 sgd_solver.cpp:120]     Element Sparsity %: 
0.8	0	47.696	0	91.0537	32	9.7	0	
I0929 13:18:01.980545  9926 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	10	0	49.125	0	6	0	
I0929 13:18:01.981166  9926 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	10	0	48.8	32	0	0	
I0929 13:18:01.985745  9926 sgd_solver.cpp:153]       Block Sparsity %: 
(25,5):0;		(25,5):33.5;		(10,10):80.475;		(10,10):6;		
I0929 13:18:01.988073  9926 solver.cpp:260]     Total regularization terms: 0.130439 loss+regular. : 0.149407
I0929 13:18:03.746258  9926 solver.cpp:465] Snapshotting to binary proto file lenet_mjc_iter_10000.caffemodel
I0929 13:18:03.780122  9926 sgd_solver.cpp:655] Snapshotting solver state to binary proto file lenet_mjc_iter_10000.solverstate
I0929 13:18:03.805402  9926 solver.cpp:328] Iteration 10000, loss = 0.0374782
I0929 13:18:03.805454  9926 solver.cpp:348] Iteration 10000, Testing net (#0)
I0929 13:18:04.895659  9926 solver.cpp:415]     Test net output #0: accuracy = 0.9818
I0929 13:18:04.895715  9926 solver.cpp:415]     Test net output #1: loss = 0.058118 (* 1 = 0.058118 loss)
I0929 13:18:04.895730  9926 solver.cpp:333] Optimization Done.
I0929 13:18:04.895750  9926 caffe.cpp:223] Optimization Done.
